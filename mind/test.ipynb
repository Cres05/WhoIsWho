{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('test_result_llama_1225.json') as file:\n",
    "    data = json.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i-bert : autoencoding transformers\n",
      "residual gating mechanism to compose adverb-action representations : video-text retrieval models\n",
      "absolute learning progress and gaussian mixture models for automatic curriculum learning : self-supervised learning\n",
      "nlogistic-sigmoid function : feedforward networks\n",
      "models genesis : 3d representations\n",
      "hierarchical bilstm max pooling : sequence to sequence models\n",
      "focus : transformers\n",
      "procrustes : generalized linear models\n",
      "panoptic fpn : feature extractors\n",
      "metaformer : image models\n",
      "deflation : miscellaneous components\n",
      "non-local operation : image feature extractors\n",
      "kungfu : auto parallel methods\n",
      "artemisinin optimization based on malaria therapy: algorithm and applications to medical image segmentation : stochastic optimization\n",
      "spatial and channel se blocks : attention mechanisms\n",
      "residual attention network : attention mechanisms\n",
      "overfitting conditional diffusion model : meta-learning algorithms\n",
      "dfh : 2d parallel distributed methods\n",
      "model editor networks with gradient decomposition : meta-learning algorithms\n",
      "pipetransformer : 2d parallel distributed methods\n",
      "pipetransformer : distributed methods\n",
      "contextualized topic models : clustering\n",
      "hypergraph self-attention : attention mechanisms\n",
      "ft-transformer : deep tabular learning\n",
      "spatio-temporal attention lstm : attention mechanisms\n",
      "dpn block : skip connection blocks\n",
      "dynamic convolution : attention mechanisms\n",
      "polynomial : activation functions\n",
      "bilayer convolutional neural network : instance segmentation modules\n",
      "variational autoencoder : attention mechanisms\n",
      "spatial and channel-wise attention-based convolutional neural network : attention mechanisms\n",
      "paramcrop : generative video models\n",
      "spectral detuning : inference attack\n",
      "spectral detuning : adversarial attacks\n",
      "high-level backbone : feature extractors\n",
      "spatiotemporal point inference network : attention mechanisms\n",
      "spatiotemporal point inference network : graph representation learning\n",
      "timesformer : generative video models\n",
      "safety-llamas : generative training\n",
      "roberta : autoencoding transformers\n",
      "mesh-tensorflow : intra-layer parallel\n",
      "batchchannel normalization : normalization\n",
      "bifpn : feature extractors\n",
      "bifpn : feature pyramid blocks\n",
      "monte carlo dropout : interpretability\n",
      "balanced selection : active learning\n",
      "filter response normalization : normalization\n",
      "bigbigan : self-supervised learning\n",
      "self-cure network : regularization\n",
      "voxel r-cnn : point cloud models\n",
      "spatial attention module : image model blocks\n",
      "variational inference : dimensionality reduction\n",
      "mdtvsfa : video quality models\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for query in data:\n",
    "    for parent in query['true_parents']:\n",
    "        if parent not in query['predictions']:\n",
    "            print(query['query'] + ' : ' + parent)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
