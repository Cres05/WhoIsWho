[
    {
        "query": "gpt-2",
        "true_parents": [
            "transformers",
            "autoregressive transformers"
        ],
        "predictions": [
            "language models",
            "autoregressive transformers",
            "language model pre-training",
            "transformers",
            "generative sequence models",
            "sequence to sequence models",
            "code generation transformers",
            "likelihood-based generative models",
            "textual inference models",
            "generative models"
        ]
    },
    {
        "query": "adversarially learned inference",
        "true_parents": [
            "generative models"
        ],
        "predictions": [
            "generative models",
            "textual inference models",
            "autoencoding transformers",
            "image generation models",
            "generative adversarial networks",
            "likelihood-based generative models",
            "discriminators",
            "generative sequence models",
            "statistical inference",
            "generative training"
        ]
    },
    {
        "query": "sparse evolutionary training",
        "true_parents": [
            "sparsity"
        ],
        "predictions": [
            "model compression",
            "sparsity",
            "adaptive computation",
            "optimization",
            "meta-learning algorithms",
            "regularization",
            "light-weight neural networks",
            "robust training",
            "mask branches",
            "output functions"
        ]
    },
    {
        "query": "i-bert",
        "true_parents": [
            "transformers",
            "autoencoding transformers"
        ],
        "predictions": [
            "language models",
            "textual inference models",
            "transformers",
            "model compression",
            "text instance representations",
            "document understanding models",
            "contextualized word embeddings",
            "autoregressive transformers",
            "document embeddings",
            "sequence to sequence models"
        ]
    },
    {
        "query": "deepvit",
        "true_parents": [
            "vision transformers",
            "image models"
        ],
        "predictions": [
            "transformers",
            "vision transformers",
            "synthesized attention mechanisms",
            "video recognition models",
            "image model blocks",
            "long-range interaction layers",
            "autoencoding transformers",
            "attention modules",
            "image models",
            "backbone architectures"
        ]
    },
    {
        "query": "ternary weight splitting",
        "true_parents": [
            "ternarization"
        ],
        "predictions": [
            "ternarization",
            "model compression",
            "language models",
            "document understanding models",
            "binary neural networks",
            "language model pre-training",
            "loss functions",
            "textual inference models",
            "transformers",
            "text classification models"
        ]
    },
    {
        "query": "ape-x dqn",
        "true_parents": [
            "q-learning networks"
        ],
        "predictions": [
            "distributed reinforcement learning",
            "meta-learning algorithms",
            "reinforcement learning frameworks",
            "actor-critic algorithms",
            "offline reinforcement learning methods",
            "hybrid parallel methods",
            "policy gradient methods",
            "off-policy td control",
            "randomized value functions",
            "control and decision systems"
        ]
    },
    {
        "query": "switch ffn",
        "true_parents": [
            "feedforward networks"
        ],
        "predictions": [
            "mixture-of-experts",
            "feedforward networks",
            "parameter sharing",
            "transformers",
            "sequence to sequence models",
            "long-range interaction layers",
            "output functions",
            "autoregressive transformers",
            "gated linear networks",
            "light-weight neural networks"
        ]
    },
    {
        "query": "residual gating mechanism to compose adverb-action representations",
        "true_parents": [
            "video-text retrieval models"
        ],
        "predictions": [
            "skip connections",
            "skip connection blocks",
            "representation learning",
            "language model components",
            "gated linear networks",
            "text instance representations",
            "feature extractors",
            "long-range interaction layers",
            "action recognition models",
            "output functions"
        ]
    },
    {
        "query": "animatable reconstruction of clothed humans",
        "true_parents": [
            "3d reconstruction"
        ],
        "predictions": [
            "3d reconstruction",
            "image manipulation models",
            "image generation models",
            "3d representations",
            "image models",
            "motion prediction models",
            "pose estimation blocks",
            "generative video models",
            "image restoration models",
            "cad design models"
        ]
    },
    {
        "query": "neighborhood attention",
        "true_parents": [
            "attention modules",
            "attention patterns",
            "attention mechanisms"
        ],
        "predictions": [
            "attention modules",
            "attention patterns",
            "localization models",
            "image model blocks",
            "synthesized attention mechanisms",
            "attention mechanisms",
            "attention",
            "image models",
            "vision transformers",
            "long-range interaction layers"
        ]
    },
    {
        "query": "adaptive early-learning correction",
        "true_parents": [
            "semantic segmentation models"
        ],
        "predictions": [
            "label correction",
            "image segmentation models",
            "semantic segmentation models",
            "medical image models",
            "semantic segmentation modules",
            "interactive semantic segmentation models",
            "document understanding models",
            "instance segmentation models",
            "generalization",
            "video object segmentation models"
        ]
    },
    {
        "query": "adversarial graph contrastive learning",
        "true_parents": [
            "graph representation learning"
        ],
        "predictions": [
            "graph models",
            "graph embeddings",
            "robust training",
            "graph representation learning",
            "adversarial training",
            "graph data augmentation",
            "representation learning",
            "self-supervised learning",
            "generalization",
            "structured prediction"
        ]
    },
    {
        "query": "color jitter",
        "true_parents": [
            "image data augmentation"
        ],
        "predictions": [
            "image data augmentation",
            "video data augmentation",
            "image manipulation models",
            "text data augmentation",
            "generalization",
            "feature extractors",
            "image representations",
            "image quality models",
            "image models",
            "image restoration models"
        ]
    },
    {
        "query": "dilated convolution with learnable spacings",
        "true_parents": [
            "convolutions"
        ],
        "predictions": [
            "convolutions",
            "convolutional neural networks",
            "semantic segmentation modules",
            "feature extractors",
            "long-range interaction layers",
            "medical image models",
            "image models",
            "semantic segmentation models",
            "image model blocks",
            "explainable cnns"
        ]
    },
    {
        "query": "retrace",
        "true_parents": [
            "value function estimation"
        ],
        "predictions": [
            "offline reinforcement learning methods",
            "value function estimation",
            "off-policy td control",
            "eligibility traces",
            "q-learning networks",
            "reinforcement learning frameworks",
            "output functions",
            "learning rate schedules",
            "actor-critic algorithms",
            "motion prediction models"
        ]
    },
    {
        "query": "shake-shake regularization",
        "true_parents": [
            "regularization"
        ],
        "predictions": [
            "regularization",
            "robustness methods",
            "robust training",
            "image model blocks",
            "output functions",
            "generalization",
            "loss functions",
            "image data augmentation",
            "skip connections",
            "auto parallel methods"
        ]
    },
    {
        "query": "mbert",
        "true_parents": [
            "language models"
        ],
        "predictions": [
            "language models",
            "language model pre-training",
            "autoregressive transformers",
            "transformers",
            "text instance representations",
            "contextualized word embeddings",
            "language model components",
            "generative sequence models",
            "document embeddings",
            "autoencoding transformers"
        ]
    },
    {
        "query": "all-attention layer",
        "true_parents": [
            "attention modules"
        ],
        "predictions": [
            "attention mechanisms",
            "transformers",
            "attention modules",
            "attention patterns",
            "attention",
            "language model components",
            "long-range interaction layers",
            "language models",
            "synthesized attention mechanisms",
            "output functions"
        ]
    },
    {
        "query": "adversarial model perturbation",
        "true_parents": [
            "optimization"
        ],
        "predictions": [
            "robust training",
            "adversarial training",
            "loss functions",
            "generalization",
            "adversarial attacks",
            "robustness methods",
            "optimization",
            "output functions",
            "parameter norm penalties",
            "adversarial image data augmentation"
        ]
    },
    {
        "query": "lenet",
        "true_parents": [
            "convolutional neural networks"
        ],
        "predictions": [
            "convolutional neural networks",
            "backbone architectures",
            "image models",
            "feature extractors",
            "pooling operations",
            "image model blocks",
            "convolutions",
            "image feature extractors",
            "feedforward networks",
            "light-weight neural networks"
        ]
    },
    {
        "query": "instance-level meta normalization",
        "true_parents": [
            "normalization"
        ],
        "predictions": [
            "meta-learning algorithms",
            "distributions",
            "generalization",
            "text instance representations",
            "medical image models",
            "distribution approximation",
            "normalization",
            "feature extractors",
            "convolutional neural networks",
            "output functions"
        ]
    },
    {
        "query": "local interpretable model-agnostic explanations",
        "true_parents": [
            "interpretability"
        ],
        "predictions": [
            "interpretability",
            "generalization",
            "output functions",
            "feature extractors",
            "statistical inference",
            "document understanding models",
            "textual inference models",
            "rule learners",
            "explainable cnns",
            "discriminators"
        ]
    },
    {
        "query": "geglu",
        "true_parents": [
            "activation functions"
        ],
        "predictions": [
            "adaptive activation functions",
            "activation functions",
            "output functions",
            "language model components",
            "feature extractors",
            "feedforward networks",
            "generalization",
            "gated linear networks",
            "synthesized attention mechanisms",
            "adaptive computation"
        ]
    },
    {
        "query": "leverage learning",
        "true_parents": [
            "fine-tuning"
        ],
        "predictions": [
            "meta-learning algorithms",
            "generalization",
            "self-training methods",
            "lifelong learning",
            "semi-supervised learning methods",
            "offline reinforcement learning methods",
            "representation learning",
            "domain adaptation",
            "ensembling",
            "fine-tuning"
        ]
    },
    {
        "query": "push pull convolutions",
        "true_parents": [
            "convolutions"
        ],
        "predictions": [
            "convolutions",
            "convolutional neural networks",
            "feature extractors",
            "generalization",
            "image models",
            "representation learning",
            "image representations",
            "explainable cnns",
            "pooling operations",
            "textual inference models"
        ]
    },
    {
        "query": "imghum",
        "true_parents": [
            "3d representations"
        ],
        "predictions": [
            "generative models",
            "likelihood-based generative models",
            "image generation models",
            "image manipulation models",
            "generative video models",
            "image models",
            "point cloud representations",
            "autoencoding transformers",
            "image model blocks",
            "3d representations"
        ]
    },
    {
        "query": "detnet",
        "true_parents": [
            "convolutional neural networks"
        ],
        "predictions": [
            "object detection models",
            "object detection modules",
            "convolutional neural networks",
            "backbone architectures",
            "image models",
            "oriented object detection models",
            "arbitrary object detectors",
            "light-weight neural networks",
            "image model blocks",
            "roi feature extractors"
        ]
    },
    {
        "query": "absolute learning progress and gaussian mixture models for automatic curriculum learning",
        "true_parents": [
            "self-supervised learning"
        ],
        "predictions": [
            "meta-learning algorithms",
            "offline reinforcement learning methods",
            "lifelong learning",
            "output functions",
            "reinforcement learning frameworks",
            "generalization",
            "adaptive computation",
            "likelihood-based generative models",
            "hyperparameter search",
            "optimization"
        ]
    },
    {
        "query": "batch normalization",
        "true_parents": [
            "normalization"
        ],
        "predictions": [
            "regularization",
            "generalization",
            "optimization",
            "output functions",
            "feature extractors",
            "normalization",
            "activation functions",
            "image models",
            "representation learning",
            "pooling operations"
        ]
    },
    {
        "query": "groupwise point convolution",
        "true_parents": [
            "convolutions"
        ],
        "predictions": [
            "convolutions",
            "point cloud representations",
            "feature extractors",
            "graph models",
            "kernel methods",
            "convolutional neural networks",
            "generalization",
            "point cloud models",
            "output functions",
            "representation learning"
        ]
    },
    {
        "query": "agglomerative contextual decomposition",
        "true_parents": [
            "interpretability"
        ],
        "predictions": [
            "interpretability",
            "clustering",
            "feature extractors",
            "output functions",
            "generalization",
            "image decomposition models",
            "explainable cnns",
            "document understanding models",
            "representation learning",
            "textual meaning"
        ]
    },
    {
        "query": "nlogistic-sigmoid function",
        "true_parents": [
            "feedforward networks",
            "activation functions"
        ],
        "predictions": [
            "output functions",
            "generalization",
            "distributions",
            "activation functions",
            "generalized linear models",
            "math formula detection models",
            "loss functions",
            "probability distribution representation",
            "affinity functions",
            "likelihood-based generative models"
        ]
    },
    {
        "query": "models genesis",
        "true_parents": [
            "3d representations"
        ],
        "predictions": [
            "medical image models",
            "self-supervised learning",
            "autoencoding transformers",
            "image models",
            "generative models",
            "image segmentation models",
            "reversible image conversion models",
            "likelihood-based generative models",
            "representation learning",
            "image generation models"
        ]
    },
    {
        "query": "hierarchical bilstm max pooling",
        "true_parents": [
            "sequence to sequence models"
        ],
        "predictions": [
            "pooling operations",
            "textual inference models",
            "generalization",
            "recurrent neural networks",
            "text classification models",
            "feature extractors",
            "textual meaning",
            "document understanding models",
            "backbone architectures",
            "relation extraction models"
        ]
    },
    {
        "query": "fastspeech 2",
        "true_parents": [
            "text-to-speech models"
        ],
        "predictions": [
            "text-to-speech models",
            "generative audio models",
            "sequence to sequence models",
            "language models",
            "autoregressive transformers",
            "generative sequence models",
            "speech synthesis blocks",
            "speech recognition",
            "paraphrase generation models",
            "autoencoding transformers"
        ]
    },
    {
        "query": "relu6",
        "true_parents": [
            "activation functions"
        ],
        "predictions": [
            "activation functions",
            "output functions",
            "adaptive activation functions",
            "generalization",
            "feature extractors",
            "feedforward networks",
            "light-weight neural networks",
            "image model blocks",
            "loss functions",
            "convolutional neural networks"
        ]
    },
    {
        "query": "convolutional gru",
        "true_parents": [
            "recurrent neural networks"
        ],
        "predictions": [
            "recurrent neural networks",
            "convolutional neural networks",
            "convolutions",
            "feature extractors",
            "image models",
            "temporal convolutions",
            "generative sequence models",
            "sequence to sequence models",
            "output functions",
            "backbone architectures"
        ]
    },
    {
        "query": "gaussian affinity",
        "true_parents": [
            "affinity functions"
        ],
        "predictions": [
            "affinity functions",
            "generalization",
            "kernel methods",
            "distributions",
            "probability distribution representation",
            "likelihood-based generative models",
            "output functions",
            "distribution approximation",
            "state similarity metrics",
            "statistical inference"
        ]
    },
    {
        "query": "spatially separable convolution",
        "true_parents": [
            "convolutions"
        ],
        "predictions": [
            "convolutions",
            "convolutional neural networks",
            "feature extractors",
            "kernel methods",
            "image decomposition models",
            "parameter sharing",
            "image models",
            "pooling operations",
            "image feature extractors",
            "network shrinking"
        ]
    },
    {
        "query": "self-adversarial negative sampling",
        "true_parents": [
            "negative sampling"
        ],
        "predictions": [
            "negative sampling",
            "loss functions",
            "document understanding models",
            "generalization",
            "meta-learning algorithms",
            "robust training",
            "representation learning",
            "relation extraction models",
            "graph embeddings",
            "textual inference models"
        ]
    },
    {
        "query": "predator",
        "true_parents": [
            "point cloud models"
        ],
        "predictions": [
            "point cloud representations",
            "output functions",
            "representation learning",
            "3d representations",
            "point cloud models",
            "generalization",
            "motion prediction models",
            "feature extractors",
            "attention modules",
            "3d object detection models"
        ]
    },
    {
        "query": "focus",
        "true_parents": [
            "transformers"
        ],
        "predictions": [
            "generalization",
            "attention mechanisms",
            "textual meaning",
            "interpretability",
            "topic embeddings",
            "exploration strategies",
            "prioritized sampling",
            "mask branches",
            "taxonomy expansion models",
            "detection assignment rules"
        ]
    },
    {
        "query": "procrustes",
        "true_parents": [
            "generalized linear models"
        ],
        "predictions": [
            "generalization",
            "geometric matching",
            "statistical inference",
            "dimensionality reduction",
            "optimization",
            "discriminators",
            "state similarity metrics",
            "localization models",
            "feature extractors",
            "medical image models"
        ]
    },
    {
        "query": "panoptic fpn",
        "true_parents": [
            "feature extractors"
        ],
        "predictions": [
            "image segmentation models",
            "semantic segmentation modules",
            "video panoptic segmentation models",
            "instance segmentation models",
            "semantic segmentation models",
            "object detection models",
            "video instance segmentation models",
            "instance segmentation modules",
            "object detection modules",
            "image model blocks"
        ]
    },
    {
        "query": "shufflenet",
        "true_parents": [
            "light-weight neural networks",
            "convolutional neural networks"
        ],
        "predictions": [
            "light-weight neural networks",
            "image models",
            "backbone architectures",
            "convolutional neural networks",
            "convolutions",
            "model compression",
            "video recognition models",
            "image model blocks",
            "image manipulation models",
            "generalization"
        ]
    },
    {
        "query": "boundary-aware segmentation network",
        "true_parents": [
            "semantic segmentation models"
        ],
        "predictions": [
            "semantic segmentation modules",
            "image segmentation models",
            "semantic segmentation models",
            "instance segmentation modules",
            "convolutional neural networks",
            "image semantic segmentation metric",
            "instance segmentation models",
            "medical image models",
            "image models",
            "image model blocks"
        ]
    },
    {
        "query": "pointer network",
        "true_parents": [
            "sequence to sequence models",
            "recurrent neural networks"
        ],
        "predictions": [
            "generative sequence models",
            "sequence to sequence models",
            "output functions",
            "attention mechanisms",
            "structured prediction",
            "graph models",
            "generative models",
            "sequence decoding methods",
            "recurrent neural networks",
            "textual inference models"
        ]
    },
    {
        "query": "masked modeling duo",
        "true_parents": [
            "self-supervised learning"
        ],
        "predictions": [
            "generative audio models",
            "self-supervised learning",
            "representation learning",
            "autoencoding transformers",
            "multi-modal methods",
            "semi-supervised learning methods",
            "speech enhancement",
            "feature extractors",
            "output functions",
            "generative sequence models"
        ]
    },
    {
        "query": "bottleneck residual block",
        "true_parents": [
            "skip connection blocks",
            "image model blocks"
        ],
        "predictions": [
            "skip connections",
            "skip connection blocks",
            "backbone architectures",
            "image model blocks",
            "convolutional neural networks",
            "image models",
            "convolutions",
            "model compression",
            "light-weight neural networks",
            "feature extractors"
        ]
    },
    {
        "query": "metaformer",
        "true_parents": [
            "image models"
        ],
        "predictions": [
            "transformers",
            "language models",
            "generative sequence models",
            "autoregressive transformers",
            "autoencoding transformers",
            "synthesized attention mechanisms",
            "document understanding models",
            "textual inference models",
            "attention mechanisms",
            "language model pre-training"
        ]
    },
    {
        "query": "deflation",
        "true_parents": [
            "miscellaneous components"
        ],
        "predictions": [
            "convolutional neural networks",
            "image models",
            "convolutions",
            "video recognition models",
            "pooling operations",
            "backbone architectures",
            "model compression",
            "image manipulation models",
            "image model blocks",
            "temporal convolutions"
        ]
    },
    {
        "query": "non-local operation",
        "true_parents": [
            "image feature extractors"
        ],
        "predictions": [
            "long-range interaction layers",
            "output functions",
            "feature extractors",
            "skip connections",
            "attention modules",
            "attention mechanisms",
            "representation learning",
            "pooling operations",
            "attention",
            "skip connection blocks"
        ]
    },
    {
        "query": "complex with n3 regularizer and relation prediction objective",
        "true_parents": [
            "graph embeddings"
        ],
        "predictions": [
            "graph models",
            "parameter norm penalties",
            "regularization",
            "loss functions",
            "generalization",
            "output functions",
            "graph embeddings",
            "graph representation learning",
            "relation extraction models",
            "meta-learning algorithms"
        ]
    },
    {
        "query": "talking-heads attention",
        "true_parents": [
            "attention modules"
        ],
        "predictions": [
            "attention modules",
            "synthesized attention mechanisms",
            "transformers",
            "attention patterns",
            "language model components",
            "attention mechanisms",
            "long-range interaction layers",
            "language models",
            "attention",
            "sequence to sequence models"
        ]
    },
    {
        "query": "augmix",
        "true_parents": [
            "image data augmentation"
        ],
        "predictions": [
            "image data augmentation",
            "video data augmentation",
            "image manipulation models",
            "image models",
            "robust training",
            "medical image models",
            "image representations",
            "image restoration models",
            "image model blocks",
            "generalization"
        ]
    },
    {
        "query": "message passing neural network",
        "true_parents": [
            "graph models"
        ],
        "predictions": [
            "graph models",
            "graph representation learning",
            "graph embeddings",
            "structured prediction",
            "graphics models",
            "output functions",
            "representation learning",
            "feature extractors",
            "generative models",
            "document understanding models"
        ]
    },
    {
        "query": "kungfu",
        "true_parents": [
            "distributed methods",
            "auto parallel methods"
        ],
        "predictions": [
            "adaptive computation",
            "hybrid parallel methods",
            "distributed methods",
            "control and decision systems",
            "generalization",
            "asynchronous data parallel",
            "parameter server methods",
            "optimization",
            "meta-learning algorithms",
            "output functions"
        ]
    },
    {
        "query": "simple neural attention meta-learner",
        "true_parents": [
            "recurrent neural networks"
        ],
        "predictions": [
            "meta-learning algorithms",
            "synthesized attention mechanisms",
            "motion prediction models",
            "attention modules",
            "offline reinforcement learning methods",
            "temporal convolutions",
            "long-range interaction layers",
            "sequence to sequence models",
            "representation learning",
            "convolutional neural networks"
        ]
    },
    {
        "query": "amsbound",
        "true_parents": [
            "stochastic optimization"
        ],
        "predictions": [
            "learning rate schedules",
            "adaptive computation",
            "optimization",
            "robust training",
            "large batch optimization",
            "hybrid optimization",
            "stochastic optimization",
            "robustness methods",
            "generalization",
            "meta-learning algorithms"
        ]
    },
    {
        "query": "pgc-dgcnn",
        "true_parents": [
            "graph models"
        ],
        "predictions": [
            "graph models",
            "convolutional neural networks",
            "graph embeddings",
            "convolutions",
            "point cloud representations",
            "feature extractors",
            "graph representation learning",
            "document understanding models",
            "long-range interaction layers",
            "graph data augmentation"
        ]
    },
    {
        "query": "artemisinin optimization based on malaria therapy: algorithm and applications to medical image segmentation",
        "true_parents": [
            "stochastic optimization"
        ],
        "predictions": [
            "optimization",
            "hybrid optimization",
            "medical image models",
            "heuristic search algorithms",
            "image segmentation models",
            "adaptive computation",
            "output functions",
            "semantic segmentation modules",
            "meta-learning algorithms",
            "generalization"
        ]
    },
    {
        "query": "population based training",
        "true_parents": [
            "optimization",
            "hyperparameter search"
        ],
        "predictions": [
            "optimization",
            "meta-learning algorithms",
            "parameter sharing",
            "adaptive computation",
            "hyperparameter search",
            "generalization",
            "distributed methods",
            "output functions",
            "hybrid optimization",
            "neural architecture search"
        ]
    },
    {
        "query": "spatial and channel se blocks",
        "true_parents": [
            "attention mechanisms"
        ],
        "predictions": [
            "image model blocks",
            "synthesized attention mechanisms",
            "semantic segmentation modules",
            "attention modules",
            "semantic segmentation models",
            "image segmentation models",
            "convolutional neural networks",
            "feature extractors",
            "attention patterns",
            "image representations"
        ]
    },
    {
        "query": "tree ensemble to rules",
        "true_parents": [
            "interpretability"
        ],
        "predictions": [
            "rule-based systems",
            "interpretability",
            "rule learners",
            "output functions",
            "document understanding models",
            "ensembling",
            "feature extractors",
            "non-parametric classification",
            "textual inference models",
            "detection assignment rules"
        ]
    },
    {
        "query": "balanced l1 loss",
        "true_parents": [
            "loss functions"
        ],
        "predictions": [
            "loss functions",
            "object detection models",
            "output functions",
            "object detection modules",
            "optimization",
            "localization models",
            "robust training",
            "discriminators",
            "parameter norm penalties",
            "regularization"
        ]
    },
    {
        "query": "residual attention network",
        "true_parents": [
            "attention mechanisms"
        ],
        "predictions": [
            "skip connections",
            "convolutional neural networks",
            "skip connection blocks",
            "attention modules",
            "backbone architectures",
            "image model blocks",
            "image models",
            "synthesized attention mechanisms",
            "medical image models",
            "video recognition models"
        ]
    },
    {
        "query": "global-local attention",
        "true_parents": [
            "attention mechanisms"
        ],
        "predictions": [
            "attention patterns",
            "attention mechanisms",
            "attention modules",
            "attention",
            "synthesized attention mechanisms",
            "long-range interaction layers",
            "language models",
            "language model components",
            "transformers",
            "sequence to sequence models"
        ]
    },
    {
        "query": "fastformer",
        "true_parents": [
            "transformers"
        ],
        "predictions": [
            "transformers",
            "autoregressive transformers",
            "long-range interaction layers",
            "language models",
            "sequence to sequence models",
            "synthesized attention mechanisms",
            "autoencoding transformers",
            "attention mechanisms",
            "generative sequence models",
            "attention modules"
        ]
    },
    {
        "query": "automatic structured variational inference",
        "true_parents": [
            "variational optimization"
        ],
        "predictions": [
            "approximate inference",
            "likelihood-based generative models",
            "generative models",
            "distribution approximation",
            "statistical inference",
            "probability distribution representation",
            "structured prediction",
            "variational optimization",
            "output functions",
            "generalization"
        ]
    },
    {
        "query": "glove embeddings",
        "true_parents": [
            "static word embeddings",
            "word embeddings"
        ],
        "predictions": [
            "word embeddings",
            "static word embeddings",
            "text instance representations",
            "document embeddings",
            "generalization",
            "textual meaning",
            "feature extractors",
            "representation learning",
            "language model components",
            "topic embeddings"
        ]
    },
    {
        "query": "overfitting conditional diffusion model",
        "true_parents": [
            "meta-learning algorithms"
        ],
        "predictions": [
            "diffusion models",
            "generative models",
            "likelihood-based generative models",
            "generalization",
            "generative sequence models",
            "distribution approximation",
            "generative audio models",
            "image generation models",
            "language models",
            "generative training"
        ]
    },
    {
        "query": "dfh",
        "true_parents": [
            "2d parallel distributed methods"
        ],
        "predictions": [
            "generalization",
            "interpretability",
            "label correction",
            "lifelong learning",
            "miscellaneous components",
            "paraphrase generation models",
            "question answering models",
            "anchor generation modules",
            "out-of-distribution example detection",
            "document summary evaluation"
        ]
    },
    {
        "query": "retinanet-rs",
        "true_parents": [
            "one-stage object detection models",
            "object detection models"
        ],
        "predictions": [
            "object detection models",
            "object detection modules",
            "convolutional neural networks",
            "oriented object detection models",
            "medical image models",
            "image models",
            "arbitrary object detectors",
            "one-stage object detection models",
            "backbone architectures",
            "image model blocks"
        ]
    },
    {
        "query": "siamese network",
        "true_parents": [
            "twin networks"
        ],
        "predictions": [
            "twin networks",
            "image models",
            "discriminators",
            "parameter sharing",
            "generalization",
            "convolutional neural networks",
            "output functions",
            "representation learning",
            "feature extractors",
            "textual inference models"
        ]
    },
    {
        "query": "pixelcnn",
        "true_parents": [
            "generative models",
            "likelihood-based generative models"
        ],
        "predictions": [
            "likelihood-based generative models",
            "generative models",
            "image models",
            "image generation models",
            "generative sequence models",
            "image manipulation models",
            "convolutional neural networks",
            "image decomposition models",
            "convolutions",
            "graphics models"
        ]
    },
    {
        "query": "cspdensenet",
        "true_parents": [
            "convolutional neural networks"
        ],
        "predictions": [
            "convolutional neural networks",
            "object detection models",
            "image models",
            "backbone architectures",
            "object detection modules",
            "medical image models",
            "video recognition models",
            "image model blocks",
            "feature extractors",
            "oriented object detection models"
        ]
    },
    {
        "query": "model editor networks with gradient decomposition",
        "true_parents": [
            "meta-learning algorithms"
        ],
        "predictions": [
            "interpretability",
            "explainable cnns",
            "output functions",
            "graph models",
            "generalization",
            "sequence editing models",
            "cad design models",
            "feature extractors",
            "representation learning",
            "graph representation learning"
        ]
    },
    {
        "query": "mixing adam and sgd",
        "true_parents": [
            "stochastic optimization"
        ],
        "predictions": [
            "learning rate schedules",
            "hybrid optimization",
            "optimization",
            "stochastic optimization",
            "adaptive computation",
            "large batch optimization",
            "meta-learning algorithms",
            "generalization",
            "parameter server methods",
            "hybrid parallel methods"
        ]
    },
    {
        "query": "pipetransformer",
        "true_parents": [
            "hybrid parallel methods",
            "distributed methods",
            "2d parallel distributed methods"
        ],
        "predictions": [
            "hybrid parallel methods",
            "language models",
            "auto parallel methods",
            "sequence to sequence models",
            "transformers",
            "attention mechanisms",
            "autoregressive transformers",
            "code generation transformers",
            "autoencoding transformers",
            "distributed methods"
        ]
    },
    {
        "query": "contextualized topic models",
        "true_parents": [
            "topic embeddings",
            "clustering",
            "document embeddings",
            "contextualized word embeddings"
        ],
        "predictions": [
            "document understanding models",
            "topic embeddings",
            "language models",
            "text instance representations",
            "autoencoding transformers",
            "generative models",
            "language model pre-training",
            "likelihood-based generative models",
            "word embeddings",
            "textual inference models"
        ]
    },
    {
        "query": "reformer",
        "true_parents": [
            "transformers"
        ],
        "predictions": [
            "transformers",
            "autoencoding transformers",
            "skip connections",
            "language models",
            "sequence to sequence models",
            "synthesized attention mechanisms",
            "document understanding models",
            "skip connection blocks",
            "autoregressive transformers",
            "representation learning"
        ]
    },
    {
        "query": "spherical graph convolutional network",
        "true_parents": [
            "graph models"
        ],
        "predictions": [
            "graph models",
            "graph embeddings",
            "convolutional neural networks",
            "graph representation learning",
            "convolutions",
            "feature extractors",
            "output functions",
            "document understanding models",
            "representation learning",
            "image models"
        ]
    },
    {
        "query": "gpipe",
        "true_parents": [
            "synchronous pipeline parallel",
            "distributed methods",
            "model parallel methods"
        ],
        "predictions": [
            "model parallel methods",
            "synchronous pipeline parallel",
            "hybrid parallel methods",
            "distributed methods",
            "auto parallel methods",
            "image models",
            "output functions",
            "sharded data parallel methods",
            "likelihood-based generative models",
            "backbone architectures"
        ]
    },
    {
        "query": "hypergraph self-attention",
        "true_parents": [
            "attention mechanisms"
        ],
        "predictions": [
            "action recognition models",
            "graph models",
            "graph embeddings",
            "long-range interaction layers",
            "graph representation learning",
            "synthesized attention mechanisms",
            "attention modules",
            "motion prediction models",
            "action recognition blocks",
            "structured prediction"
        ]
    },
    {
        "query": "ft-transformer",
        "true_parents": [
            "deep tabular learning"
        ],
        "predictions": [
            "autoencoding transformers",
            "transformers",
            "sequence to sequence models",
            "autoregressive transformers",
            "feature extractors",
            "language models",
            "document understanding models",
            "table question answering models",
            "backbone architectures",
            "attention mechanisms"
        ]
    },
    {
        "query": "natural gradient descent",
        "true_parents": [
            "optimization"
        ],
        "predictions": [
            "optimization",
            "adaptive computation",
            "output functions",
            "likelihood-based generative models",
            "meta-learning algorithms",
            "loss functions",
            "statistical inference",
            "variational optimization",
            "stochastic optimization",
            "generalization"
        ]
    },
    {
        "query": "spatio-temporal attention lstm",
        "true_parents": [
            "attention mechanisms"
        ],
        "predictions": [
            "action recognition models",
            "action recognition blocks",
            "video recognition models",
            "recurrent neural networks",
            "attention modules",
            "attention patterns",
            "motion prediction models",
            "synthesized attention mechanisms",
            "video-text retrieval models",
            "attention"
        ]
    },
    {
        "query": "multi-dconv-head attention",
        "true_parents": [
            "attention modules"
        ],
        "predictions": [
            "attention modules",
            "attention mechanisms",
            "attention patterns",
            "synthesized attention mechanisms",
            "transformers",
            "convolutions",
            "language model components",
            "document understanding models",
            "sequence to sequence models",
            "image model blocks"
        ]
    },
    {
        "query": "musiq",
        "true_parents": [
            "vision transformers",
            "image quality models"
        ],
        "predictions": [
            "image quality models",
            "transformers",
            "image model blocks",
            "vision and language pre-trained models",
            "synthesized attention mechanisms",
            "image models",
            "image representations",
            "sequence to sequence models",
            "autoencoding transformers",
            "attention mechanisms"
        ]
    },
    {
        "query": "linear layer",
        "true_parents": [
            "feedforward networks"
        ],
        "predictions": [
            "feature extractors",
            "output functions",
            "feedforward networks",
            "generalized linear models",
            "backbone architectures",
            "generalization",
            "language model components",
            "activation functions",
            "representation learning",
            "dimensionality reduction"
        ]
    },
    {
        "query": "base boosting",
        "true_parents": [
            "generalized additive models"
        ],
        "predictions": [
            "ensembling",
            "output functions",
            "non-parametric regression",
            "generalization",
            "generalized additive models",
            "statistical inference",
            "optimization",
            "document understanding models",
            "discriminators",
            "generalized linear models"
        ]
    },
    {
        "query": "meuzz",
        "true_parents": [
            "hybrid optimization",
            "hybrid fuzzing"
        ],
        "predictions": [
            "hybrid fuzzing",
            "hybrid parallel methods",
            "hybrid optimization",
            "generalization",
            "adaptive computation",
            "textual inference models",
            "meta-learning algorithms",
            "semi-supervised learning methods",
            "domain adaptation",
            "out-of-distribution example detection"
        ]
    },
    {
        "query": "dpn block",
        "true_parents": [
            "skip connection blocks",
            "image model blocks"
        ],
        "predictions": [
            "image model blocks",
            "convolutional neural networks",
            "image models",
            "backbone architectures",
            "image feature extractors",
            "feature extractors",
            "image representations",
            "convolutions",
            "document understanding models",
            "skip connections"
        ]
    },
    {
        "query": "rotary position embedding",
        "true_parents": [
            "position embeddings"
        ],
        "predictions": [
            "position embeddings",
            "graph embeddings",
            "text instance representations",
            "transformers",
            "motion prediction models",
            "synthesized attention mechanisms",
            "attention patterns",
            "long-range interaction layers",
            "language model components",
            "sequence to sequence models"
        ]
    },
    {
        "query": "continual learning through adjustment suppression and sparsity promotion",
        "true_parents": [
            "lifelong learning"
        ],
        "predictions": [
            "lifelong learning",
            "generalization",
            "meta-learning algorithms",
            "regularization",
            "adaptive computation",
            "optimization",
            "representation learning",
            "network shrinking",
            "sparsity",
            "robust training"
        ]
    },
    {
        "query": "heterogeneous molecular graph neural network",
        "true_parents": [
            "graph models"
        ],
        "predictions": [
            "graph models",
            "graph embeddings",
            "graph representation learning",
            "representation learning",
            "quantum methods",
            "synthesized attention mechanisms",
            "output functions",
            "generalization",
            "structured prediction",
            "graph data augmentation"
        ]
    },
    {
        "query": "audiovisual slowfast network",
        "true_parents": [
            "video recognition models",
            "multi-modal methods"
        ],
        "predictions": [
            "video recognition models",
            "video-text retrieval models",
            "multi-modal methods",
            "vision and language pre-trained models",
            "convolutional neural networks",
            "feature extractors",
            "action recognition models",
            "image models",
            "representation learning",
            "backbone architectures"
        ]
    },
    {
        "query": "dynamic convolution",
        "true_parents": [
            "attention mechanisms"
        ],
        "predictions": [
            "convolutional neural networks",
            "convolutions",
            "temporal convolutions",
            "image models",
            "synthesized attention mechanisms",
            "model compression",
            "attention modules",
            "light-weight neural networks",
            "explainable cnns",
            "feature extractors"
        ]
    },
    {
        "query": "swiglu",
        "true_parents": [
            "activation functions"
        ],
        "predictions": [
            "adaptive activation functions",
            "activation functions",
            "output functions",
            "math formula detection models",
            "feedforward networks",
            "feature extractors",
            "generalization",
            "loss functions",
            "synthesized attention mechanisms",
            "adaptive computation"
        ]
    },
    {
        "query": "window-based discriminator",
        "true_parents": [
            "discriminators"
        ],
        "predictions": [
            "discriminators",
            "generative audio models",
            "generative adversarial networks",
            "generative models",
            "generative sequence models",
            "feature extractors",
            "likelihood-based generative models",
            "speech separation models",
            "output functions",
            "image generation models"
        ]
    },
    {
        "query": "denoised smoothing",
        "true_parents": [
            "robustness methods"
        ],
        "predictions": [
            "image restoration models",
            "robust training",
            "speech enhancement",
            "output functions",
            "generalization",
            "document understanding models",
            "text classification models",
            "discriminators",
            "image denoising models",
            "robustness methods"
        ]
    },
    {
        "query": "gradient harmonizing mechanism c",
        "true_parents": [
            "loss functions"
        ],
        "predictions": [
            "loss functions",
            "output functions",
            "adaptive activation functions",
            "discriminators",
            "adaptive computation",
            "learning rate schedules",
            "value function estimation",
            "generalization",
            "optimization",
            "robust training"
        ]
    },
    {
        "query": "large-scale information network embedding",
        "true_parents": [
            "graph embeddings"
        ],
        "predictions": [
            "graph embeddings",
            "graph models",
            "graph representation learning",
            "representation learning",
            "optimization",
            "generalization",
            "output functions",
            "distributed methods",
            "feature extractors",
            "dimensionality reduction"
        ]
    },
    {
        "query": "inception-c",
        "true_parents": [
            "image model blocks"
        ],
        "predictions": [
            "image model blocks",
            "image feature extractors",
            "feature extractors",
            "convolutional neural networks",
            "medical image models",
            "image models",
            "backbone architectures",
            "roi feature extractors",
            "object detection modules",
            "image manipulation models"
        ]
    },
    {
        "query": "spreadsheetcoder",
        "true_parents": [
            "spreadsheet formula prediction models"
        ],
        "predictions": [
            "code generation transformers",
            "spreadsheet formula prediction models",
            "sequence to sequence models",
            "language models",
            "table question answering models",
            "textual inference models",
            "autoregressive transformers",
            "math formula detection models",
            "document understanding models",
            "structured prediction"
        ]
    },
    {
        "query": "polynomial",
        "true_parents": [
            "activation functions"
        ],
        "predictions": [
            "math formula detection models",
            "generalization",
            "output functions",
            "counting methods",
            "distributions",
            "textual inference models",
            "generalized linear models",
            "textual meaning",
            "text classification models",
            "loss functions"
        ]
    },
    {
        "query": "masked autoencoder",
        "true_parents": [
            "self-supervised learning"
        ],
        "predictions": [
            "autoencoding transformers",
            "generative models",
            "representation learning",
            "self-supervised learning",
            "language models",
            "feature extractors",
            "generalization",
            "textual inference models",
            "likelihood-based generative models",
            "text instance representations"
        ]
    },
    {
        "query": "structure retaining cyclegan",
        "true_parents": [
            "image generation models"
        ],
        "predictions": [
            "reversible image conversion models",
            "conditional image-to-image translation models",
            "image manipulation models",
            "image generation models",
            "image restoration models",
            "style transfer models",
            "image models",
            "medical image models",
            "domain adaptation",
            "generalization"
        ]
    },
    {
        "query": "twins-svt",
        "true_parents": [
            "vision transformers"
        ],
        "predictions": [
            "vision transformers",
            "video-text retrieval models",
            "video recognition models",
            "synthesized attention mechanisms",
            "transformers",
            "attention modules",
            "image model blocks",
            "vision and language pre-trained models",
            "long-range interaction layers",
            "autoencoding transformers"
        ]
    },
    {
        "query": "clusterfit",
        "true_parents": [
            "self-supervised learning"
        ],
        "predictions": [
            "self-supervised learning",
            "clustering",
            "representation learning",
            "semi-supervised learning methods",
            "feature extractors",
            "image models",
            "image representations",
            "image feature extractors",
            "medical image models",
            "generalization"
        ]
    },
    {
        "query": "wavegan",
        "true_parents": [
            "generative audio models"
        ],
        "predictions": [
            "generative audio models",
            "generative models",
            "generative adversarial networks",
            "likelihood-based generative models",
            "generative sequence models",
            "image generation models",
            "text-to-speech models",
            "convolutions",
            "convolutional neural networks",
            "generative training"
        ]
    },
    {
        "query": "quanttree histograms",
        "true_parents": [
            "distribution approximation"
        ],
        "predictions": [
            "statistical inference",
            "non-parametric classification",
            "generalization",
            "distribution approximation",
            "distributions",
            "probability distribution representation",
            "counting methods",
            "non-parametric regression",
            "robustness methods",
            "output functions"
        ]
    },
    {
        "query": "bilayer convolutional neural network",
        "true_parents": [
            "instance segmentation modules"
        ],
        "predictions": [
            "convolutional neural networks",
            "image models",
            "feature extractors",
            "convolutions",
            "medical image models",
            "image feature extractors",
            "image representations",
            "backbone architectures",
            "image model blocks",
            "pooling operations"
        ]
    },
    {
        "query": "fastspeech 2s",
        "true_parents": [
            "text-to-speech models"
        ],
        "predictions": [
            "text-to-speech models",
            "generative audio models",
            "sequence to sequence models",
            "speech synthesis blocks",
            "language models",
            "generative sequence models",
            "speech recognition",
            "autoregressive transformers",
            "likelihood-based generative models",
            "generative models"
        ]
    },
    {
        "query": "deeplabv2",
        "true_parents": [
            "semantic segmentation models"
        ],
        "predictions": [
            "semantic segmentation modules",
            "semantic segmentation models",
            "image segmentation models",
            "convolutional neural networks",
            "image semantic segmentation metric",
            "image models",
            "instance segmentation modules",
            "backbone architectures",
            "instance segmentation models",
            "image model blocks"
        ]
    },
    {
        "query": "second-order clipped stochastic optimization",
        "true_parents": [
            "optimization"
        ],
        "predictions": [
            "optimization",
            "stochastic optimization",
            "meta-learning algorithms",
            "hybrid optimization",
            "adaptive computation",
            "heuristic search algorithms",
            "generalization",
            "value function estimation",
            "learning rate schedules",
            "loss functions"
        ]
    },
    {
        "query": "l1 regularization",
        "true_parents": [
            "parameter norm penalties",
            "regularization"
        ],
        "predictions": [
            "parameter norm penalties",
            "regularization",
            "loss functions",
            "sparsity",
            "optimization",
            "network shrinking",
            "model compression",
            "generalization",
            "pruning",
            "output functions"
        ]
    },
    {
        "query": "global-and-local attention",
        "true_parents": [
            "attention mechanisms"
        ],
        "predictions": [
            "attention modules",
            "attention patterns",
            "explainable cnns",
            "synthesized attention mechanisms",
            "image model blocks",
            "image models",
            "document understanding models",
            "attention",
            "video-text retrieval models",
            "long-range interaction layers"
        ]
    },
    {
        "query": "cspdensenet-elastic",
        "true_parents": [
            "convolutional neural networks"
        ],
        "predictions": [
            "object detection models",
            "backbone architectures",
            "convolutional neural networks",
            "object detection modules",
            "image models",
            "video recognition models",
            "image model blocks",
            "oriented object detection models",
            "document understanding models",
            "feature extractors"
        ]
    },
    {
        "query": "max pooling",
        "true_parents": [
            "pooling operations"
        ],
        "predictions": [
            "pooling operations",
            "feature extractors",
            "image models",
            "convolutions",
            "convolutional neural networks",
            "dimensionality reduction",
            "output functions",
            "downsampling",
            "image feature extractors",
            "image representations"
        ]
    },
    {
        "query": "vision transformer",
        "true_parents": [
            "vision transformers",
            "image models"
        ],
        "predictions": [
            "vision transformers",
            "transformers",
            "attention mechanisms",
            "image models",
            "image representations",
            "backbone architectures",
            "image model blocks",
            "image feature extractors",
            "autoencoding transformers",
            "video recognition models"
        ]
    },
    {
        "query": "variational autoencoder",
        "true_parents": [
            "generative models",
            "likelihood-based generative models",
            "attention mechanisms"
        ],
        "predictions": [
            "generative models",
            "image generation models",
            "likelihood-based generative models",
            "generalization",
            "generative sequence models",
            "generative video models",
            "autoencoding transformers",
            "approximate inference",
            "distribution approximation",
            "output functions"
        ]
    },
    {
        "query": "spatial and channel-wise attention-based convolutional neural network",
        "true_parents": [
            "attention mechanisms"
        ],
        "predictions": [
            "convolutional neural networks",
            "explainable cnns",
            "attention modules",
            "synthesized attention mechanisms",
            "document understanding models",
            "image models",
            "sequence to sequence models",
            "medical image models",
            "feature extractors",
            "generative sequence models"
        ]
    },
    {
        "query": "adahessian",
        "true_parents": [
            "optimization",
            "stochastic optimization"
        ],
        "predictions": [
            "stochastic optimization",
            "optimization",
            "adaptive computation",
            "loss functions",
            "learning rate schedules",
            "output functions",
            "generalization",
            "heuristic search algorithms",
            "hybrid optimization",
            "meta-learning algorithms"
        ]
    },
    {
        "query": "self-adjusting smooth l1 loss",
        "true_parents": [
            "loss functions"
        ],
        "predictions": [
            "loss functions",
            "object detection models",
            "adaptive activation functions",
            "adaptive computation",
            "output functions",
            "math formula detection models",
            "object detection modules",
            "robust training",
            "meta-learning algorithms",
            "oriented object detection models"
        ]
    },
    {
        "query": "visual parsing",
        "true_parents": [
            "vision and language pre-trained models"
        ],
        "predictions": [
            "vision and language pre-trained models",
            "multi-modal methods",
            "transformers",
            "image models",
            "image representations",
            "synthesized attention mechanisms",
            "document understanding models",
            "representation learning",
            "attention mechanisms",
            "language models"
        ]
    },
    {
        "query": "single headed attention rnn",
        "true_parents": [
            "language models",
            "recurrent neural networks"
        ],
        "predictions": [
            "recurrent neural networks",
            "language models",
            "generative sequence models",
            "light-weight neural networks",
            "textual inference models",
            "sequence to sequence models",
            "language model components",
            "likelihood-based generative models",
            "generative audio models",
            "backbone architectures"
        ]
    },
    {
        "query": "enhanced seq2seq autoencoder via contrastive learning",
        "true_parents": [
            "transformers"
        ],
        "predictions": [
            "sequence to sequence models",
            "autoencoding transformers",
            "generative sequence models",
            "language models",
            "paraphrase generation models",
            "transformers",
            "autoregressive transformers",
            "document understanding models",
            "textual inference models",
            "generative models"
        ]
    },
    {
        "query": "self-learning",
        "true_parents": [
            "lifelong learning"
        ],
        "predictions": [
            "lifelong learning",
            "generalization",
            "active learning",
            "self-training methods",
            "attention mechanisms",
            "meta-learning algorithms",
            "textual inference models",
            "offline reinforcement learning methods",
            "textual meaning",
            "exploration strategies"
        ]
    },
    {
        "query": "paramcrop",
        "true_parents": [
            "generative video models",
            "self-supervised learning"
        ],
        "predictions": [
            "video recognition models",
            "video data augmentation",
            "video-text retrieval models",
            "image data augmentation",
            "image manipulation models",
            "convolutional neural networks",
            "representation learning",
            "video sampling",
            "image models",
            "image representations"
        ]
    },
    {
        "query": "spectral detuning",
        "true_parents": [
            "inference attack",
            "fine-tuning",
            "adversarial attacks",
            "pre-fine-tuning weight recovery"
        ],
        "predictions": [
            "pre-fine-tuning weight recovery",
            "generative audio models",
            "image restoration models",
            "fine-tuning",
            "autoencoding transformers",
            "parameter sharing",
            "image manipulation models",
            "image generation models",
            "paraphrase generation models",
            "diffusion models"
        ]
    },
    {
        "query": "high-level backbone",
        "true_parents": [
            "feature extractors"
        ],
        "predictions": [
            "backbone architectures",
            "generalization",
            "taxonomy expansion models",
            "graph models",
            "multi-scale analysis",
            "attention mechanisms",
            "interpretability",
            "textual inference models",
            "dimensionality reduction",
            "global context modules"
        ]
    },
    {
        "query": "douzero",
        "true_parents": [
            "card game models"
        ],
        "predictions": [
            "offline reinforcement learning methods",
            "card game models",
            "distributed reinforcement learning",
            "value function estimation",
            "reinforcement learning frameworks",
            "structured prediction",
            "board game models",
            "actor-critic algorithms",
            "recurrent neural networks",
            "output functions"
        ]
    },
    {
        "query": "spatiotemporal point inference network",
        "true_parents": [
            "graph representation learning",
            "attention mechanisms"
        ],
        "predictions": [
            "textual inference models",
            "localization models",
            "motion prediction models",
            "output functions",
            "generalization",
            "statistical inference",
            "trajectory prediction models",
            "structured prediction",
            "inference extrapolation",
            "graph models"
        ]
    },
    {
        "query": "herring",
        "true_parents": [
            "distributed methods",
            "parameter server methods",
            "hybrid parallel methods"
        ],
        "predictions": [
            "parameter server methods",
            "hybrid parallel methods",
            "distributed methods",
            "data parallel methods",
            "parameter sharing",
            "sharded data parallel methods",
            "distributed communication",
            "model parallel methods",
            "distributed reinforcement learning",
            "large batch optimization"
        ]
    },
    {
        "query": "fast-yolov2",
        "true_parents": [
            "convolutional neural networks"
        ],
        "predictions": [
            "object detection models",
            "object detection modules",
            "one-stage object detection models",
            "image models",
            "convolutional neural networks",
            "oriented object detection models",
            "video recognition models",
            "arbitrary object detectors",
            "light-weight neural networks",
            "image manipulation models"
        ]
    },
    {
        "query": "child-tuning",
        "true_parents": [
            "fine-tuning"
        ],
        "predictions": [
            "fine-tuning",
            "domain adaptation",
            "language models",
            "parameter sharing",
            "hyperparameter search",
            "language model pre-training",
            "optimization",
            "mask branches",
            "transformers",
            "textual inference models"
        ]
    },
    {
        "query": "convolutional time-domain audio separation network",
        "true_parents": [
            "music source separation",
            "speech enhancement",
            "speech separation models",
            "temporal convolutions"
        ],
        "predictions": [
            "speech separation models",
            "music source separation",
            "generative audio models",
            "convolutions",
            "speech enhancement",
            "temporal convolutions",
            "convolutional neural networks",
            "feature extractors",
            "output functions",
            "audio model blocks"
        ]
    },
    {
        "query": "hybrid task cascade",
        "true_parents": [
            "instance segmentation models",
            "object detection models"
        ],
        "predictions": [
            "instance segmentation models",
            "instance segmentation modules",
            "video instance segmentation models",
            "image segmentation models",
            "semantic segmentation modules",
            "object detection models",
            "video object segmentation models",
            "semantic segmentation models",
            "image models",
            "video recognition models"
        ]
    },
    {
        "query": "residual multi-layer perceptrons",
        "true_parents": [
            "image models"
        ],
        "predictions": [
            "image models",
            "image model blocks",
            "convolutional neural networks",
            "backbone architectures",
            "skip connections",
            "feature extractors",
            "image feature extractors",
            "skip connection blocks",
            "output functions",
            "image representations"
        ]
    },
    {
        "query": "contrastive cross-view mutual information maximization",
        "true_parents": [
            "representation learning"
        ],
        "predictions": [
            "representation learning",
            "pose estimation models",
            "multi-modal methods",
            "loss functions",
            "video-text retrieval models",
            "image representations",
            "self-supervised learning",
            "6d pose estimation models",
            "pose estimation blocks",
            "motion prediction models"
        ]
    },
    {
        "query": "meta face recognition",
        "true_parents": [
            "face recognition models"
        ],
        "predictions": [
            "meta-learning algorithms",
            "face recognition models",
            "domain adaptation",
            "generalization",
            "image models",
            "discriminators",
            "representation learning",
            "lifelong learning",
            "medical image models",
            "image representations"
        ]
    },
    {
        "query": "hybrid-deconvolution",
        "true_parents": [
            "convolutional neural networks"
        ],
        "predictions": [
            "medical image models",
            "image restoration models",
            "convolutional neural networks",
            "feature extractors",
            "image models",
            "semantic segmentation modules",
            "image manipulation models",
            "convolutions",
            "image feature extractors",
            "semantic segmentation models"
        ]
    },
    {
        "query": "qhadam",
        "true_parents": [
            "stochastic optimization"
        ],
        "predictions": [
            "optimization",
            "adaptive computation",
            "learning rate schedules",
            "hybrid optimization",
            "meta-learning algorithms",
            "stochastic optimization",
            "hybrid parallel methods",
            "parameter server methods",
            "loss functions",
            "heuristic search algorithms"
        ]
    },
    {
        "query": "aggregated learning",
        "true_parents": [
            "information bottleneck"
        ],
        "predictions": [
            "generalization",
            "representation learning",
            "text classification models",
            "semi-supervised learning methods",
            "output functions",
            "lifelong learning",
            "information bottleneck",
            "feature extractors",
            "discriminators",
            "meta-learning algorithms"
        ]
    },
    {
        "query": "online normalization",
        "true_parents": [
            "normalization"
        ],
        "predictions": [
            "normalization",
            "optimization",
            "learning rate schedules",
            "generalization",
            "adaptive activation functions",
            "adaptive computation",
            "text instance representations",
            "output functions",
            "statistical inference",
            "representation learning"
        ]
    },
    {
        "query": "autoencoders",
        "true_parents": [
            "dimensionality reduction"
        ],
        "predictions": [
            "generative models",
            "autoencoding transformers",
            "representation learning",
            "feature extractors",
            "dimensionality reduction",
            "likelihood-based generative models",
            "image models",
            "output functions",
            "self-supervised learning",
            "image generation models"
        ]
    },
    {
        "query": "resnest",
        "true_parents": [
            "convolutional neural networks",
            "image models"
        ],
        "predictions": [
            "backbone architectures",
            "image models",
            "image model blocks",
            "convolutional neural networks",
            "image feature extractors",
            "skip connections",
            "video recognition models",
            "synthesized attention mechanisms",
            "skip connection blocks",
            "image representations"
        ]
    },
    {
        "query": "3d dynamic scene graph",
        "true_parents": [
            "3d representations"
        ],
        "predictions": [
            "graph models",
            "3d representations",
            "motion prediction models",
            "graphics models",
            "generalization",
            "cad design models",
            "video panoptic segmentation models",
            "point cloud representations",
            "3d reconstruction",
            "taxonomy expansion models"
        ]
    },
    {
        "query": "lbl2vec",
        "true_parents": [
            "text classification models"
        ],
        "predictions": [
            "document embeddings",
            "feature extractors",
            "representation learning",
            "text instance representations",
            "generalization",
            "document understanding models",
            "topic embeddings",
            "text classification models",
            "textual inference models",
            "sentence embeddings"
        ]
    },
    {
        "query": "timesformer",
        "true_parents": [
            "generative video models"
        ],
        "predictions": [
            "video recognition models",
            "action recognition models",
            "transformers",
            "vision transformers",
            "action recognition blocks",
            "feature extractors",
            "representation learning",
            "time series modules",
            "image feature extractors",
            "video-text retrieval models"
        ]
    },
    {
        "query": "droppath",
        "true_parents": [
            "regularization"
        ],
        "predictions": [
            "regularization",
            "parameter norm penalties",
            "skip connections",
            "skip connection blocks",
            "parameter sharing",
            "pooling operations",
            "output functions",
            "graph models",
            "feedforward networks",
            "backbone architectures"
        ]
    },
    {
        "query": "reglu",
        "true_parents": [
            "activation functions"
        ],
        "predictions": [
            "activation functions",
            "adaptive activation functions",
            "output functions",
            "feedforward networks",
            "feature extractors",
            "generalization",
            "loss functions",
            "adaptive computation",
            "generalized linear models",
            "bijective transformation"
        ]
    },
    {
        "query": "gblock",
        "true_parents": [
            "audio model blocks",
            "skip connection blocks"
        ],
        "predictions": [
            "speech synthesis blocks",
            "text-to-speech models",
            "generative audio models",
            "audio model blocks",
            "skip connection blocks",
            "temporal convolutions",
            "sequence to sequence models",
            "generative models",
            "skip connections",
            "long-range interaction layers"
        ]
    },
    {
        "query": "meta pseudo labels",
        "true_parents": [
            "semi-supervised learning methods"
        ],
        "predictions": [
            "semi-supervised learning methods",
            "self-training methods",
            "meta-learning algorithms",
            "generalization",
            "self-supervised learning",
            "label correction",
            "loss functions",
            "output functions",
            "textual inference models",
            "document understanding models"
        ]
    },
    {
        "query": "neural adjoint method",
        "true_parents": [
            "optimization"
        ],
        "predictions": [
            "output functions",
            "optimization",
            "generalization",
            "meta-learning algorithms",
            "likelihood-based generative models",
            "variational optimization",
            "adaptive computation",
            "image restoration models",
            "interpretability",
            "approximate inference"
        ]
    },
    {
        "query": "safety-llamas",
        "true_parents": [
            "generative training"
        ],
        "predictions": [
            "generalization",
            "miscellaneous components",
            "label correction",
            "taxonomy expansion models",
            "out-of-distribution example detection",
            "interpretability",
            "lifelong learning",
            "behaviour policies",
            "environment design methods",
            "imitation learning methods"
        ]
    },
    {
        "query": "accuracy-robustness area",
        "true_parents": [
            "adversarial training"
        ],
        "predictions": [
            "robust training",
            "output functions",
            "generalization",
            "discriminators",
            "loss functions",
            "text classification models",
            "adversarial attacks",
            "robustness methods",
            "out-of-distribution example detection",
            "statistical inference"
        ]
    },
    {
        "query": "adagpr",
        "true_parents": [
            "graph models"
        ],
        "predictions": [
            "graph models",
            "graph embeddings",
            "graph representation learning",
            "graph data augmentation",
            "adaptive computation",
            "document understanding models",
            "convolutions",
            "convolutional neural networks",
            "adaptive activation functions",
            "domain adaptation"
        ]
    },
    {
        "query": "hardelish",
        "true_parents": [
            "activation functions"
        ],
        "predictions": [
            "activation functions",
            "adaptive activation functions",
            "output functions",
            "feedforward networks",
            "discriminators",
            "generalization",
            "math formula detection models",
            "loss functions",
            "binary neural networks",
            "document understanding models"
        ]
    },
    {
        "query": "symbolic deep learning",
        "true_parents": [
            "interpretability",
            "graph models"
        ],
        "predictions": [
            "interpretability",
            "generalization",
            "output functions",
            "graph models",
            "representation learning",
            "statistical inference",
            "structured prediction",
            "feature extractors",
            "inference extrapolation",
            "taxonomy expansion models"
        ]
    },
    {
        "query": "cyclegan",
        "true_parents": [
            "generative models",
            "unpaired image-to-image translation",
            "generative adversarial networks"
        ],
        "predictions": [
            "reversible image conversion models",
            "generative adversarial networks",
            "generative models",
            "conditional image-to-image translation models",
            "image generation models",
            "unpaired image-to-image translation",
            "image manipulation models",
            "few-shot image-to-image translation",
            "style transfer models",
            "image models"
        ]
    },
    {
        "query": "distdgl",
        "true_parents": [
            "distributed methods"
        ],
        "predictions": [
            "graph models",
            "graph embeddings",
            "distributed methods",
            "hybrid parallel methods",
            "graph representation learning",
            "auto parallel methods",
            "data parallel methods",
            "sharded data parallel methods",
            "graph data augmentation",
            "parameter server methods"
        ]
    },
    {
        "query": "coordconv",
        "true_parents": [
            "convolutions"
        ],
        "predictions": [
            "convolutional neural networks",
            "convolutions",
            "feature extractors",
            "explainable cnns",
            "image models",
            "image manipulation models",
            "image model blocks",
            "output functions",
            "scene text models",
            "document understanding models"
        ]
    },
    {
        "query": "randomized leaky rectified linear units",
        "true_parents": [
            "activation functions"
        ],
        "predictions": [
            "adaptive activation functions",
            "activation functions",
            "output functions",
            "feature extractors",
            "loss functions",
            "initialization",
            "feedforward networks",
            "image models",
            "generalization",
            "document understanding models"
        ]
    },
    {
        "query": "r-cnn",
        "true_parents": [
            "object detection models"
        ],
        "predictions": [
            "object detection models",
            "object detection modules",
            "image models",
            "convolutional neural networks",
            "roi feature extractors",
            "image feature extractors",
            "feature extractors",
            "instance segmentation modules",
            "instance segmentation models",
            "oriented object detection models"
        ]
    },
    {
        "query": "emqap",
        "true_parents": [
            "question answering models"
        ],
        "predictions": [
            "question answering models",
            "document understanding models",
            "language models",
            "textual inference models",
            "sequence to sequence models",
            "information retrieval methods",
            "language model pre-training",
            "autoregressive transformers",
            "text classification models",
            "fine-tuning"
        ]
    },
    {
        "query": "3-augment",
        "true_parents": [
            "image data augmentation"
        ],
        "predictions": [
            "generalization",
            "graph data augmentation",
            "text augmentation",
            "trajectory data augmentation",
            "image data augmentation",
            "text data augmentation",
            "robustness methods",
            "video data augmentation",
            "prioritized sampling",
            "point cloud augmentation"
        ]
    },
    {
        "query": "roberta",
        "true_parents": [
            "transformers",
            "autoencoding transformers"
        ],
        "predictions": [
            "language models",
            "language model pre-training",
            "document understanding models",
            "transformers",
            "textual inference models",
            "autoregressive transformers",
            "generative sequence models",
            "text instance representations",
            "contextualized word embeddings",
            "language model components"
        ]
    },
    {
        "query": "bayesian reward extrapolation",
        "true_parents": [
            "bayesian reinforcement learning"
        ],
        "predictions": [
            "bayesian reinforcement learning",
            "offline reinforcement learning methods",
            "imitation learning methods",
            "meta-learning algorithms",
            "output functions",
            "statistical inference",
            "likelihood-based generative models",
            "inference extrapolation",
            "feature extractors",
            "generalization"
        ]
    },
    {
        "query": "mesh-tensorflow",
        "true_parents": [
            "intra-layer parallel",
            "distributed methods",
            "model parallel methods"
        ],
        "predictions": [
            "hybrid parallel methods",
            "mesh-based simulation models",
            "auto parallel methods",
            "data parallel methods",
            "sharded data parallel methods",
            "distributed methods",
            "model parallel methods",
            "graph models",
            "2d parallel distributed methods",
            "output functions"
        ]
    },
    {
        "query": "contrastive multiview coding",
        "true_parents": [
            "self-supervised learning"
        ],
        "predictions": [
            "self-supervised learning",
            "multi-modal methods",
            "representation learning",
            "video-text retrieval models",
            "image representations",
            "generalization",
            "semi-supervised learning methods",
            "feature extractors",
            "image models",
            "text instance representations"
        ]
    },
    {
        "query": "cross-attention module",
        "true_parents": [
            "attention modules"
        ],
        "predictions": [
            "attention modules",
            "synthesized attention mechanisms",
            "image model blocks",
            "language model components",
            "attention mechanisms",
            "attention patterns",
            "long-range interaction layers",
            "transformers",
            "vision transformers",
            "autoencoding transformers"
        ]
    },
    {
        "query": "batchchannel normalization",
        "true_parents": [
            "normalization"
        ],
        "predictions": [
            "output functions",
            "adaptive activation functions",
            "image model blocks",
            "image models",
            "loss functions",
            "large batch optimization",
            "image restoration models",
            "model compression",
            "robust training",
            "pooling operations"
        ]
    },
    {
        "query": "basicvsr",
        "true_parents": [
            "video super-resolution models"
        ],
        "predictions": [
            "image super-resolution models",
            "video super-resolution models",
            "image restoration models",
            "super-resolution models",
            "image manipulation models",
            "convolutional neural networks",
            "recurrent neural networks",
            "video interpolation models",
            "image scaling strategies",
            "video recognition models"
        ]
    },
    {
        "query": "bifpn",
        "true_parents": [
            "feature extractors",
            "feature pyramid blocks"
        ],
        "predictions": [
            "object detection models",
            "document understanding models",
            "convolutional neural networks",
            "object detection modules",
            "feature extractors",
            "scene text models",
            "semantic segmentation modules",
            "video-text retrieval models",
            "feature pyramid blocks",
            "image feature extractors"
        ]
    },
    {
        "query": "pyramid vision transformer v2",
        "true_parents": [
            "vision transformers",
            "image models"
        ],
        "predictions": [
            "vision transformers",
            "video recognition models",
            "object detection models",
            "vision and language pre-trained models",
            "transformers",
            "backbone architectures",
            "instance segmentation models",
            "video instance segmentation models",
            "image models",
            "object detection modules"
        ]
    },
    {
        "query": "wasserstein gan (gradient penalty)",
        "true_parents": [
            "generative adversarial networks"
        ],
        "predictions": [
            "generative adversarial networks",
            "generative models",
            "image generation models",
            "loss functions",
            "likelihood-based generative models",
            "discriminators",
            "generative training",
            "output functions",
            "robust training",
            "generalization"
        ]
    },
    {
        "query": "distance shrinking with angular marginalizing loss",
        "true_parents": [
            "loss functions"
        ],
        "predictions": [
            "loss functions",
            "discriminators",
            "dimensionality reduction",
            "representation learning",
            "generalization",
            "network shrinking",
            "feature extractors",
            "optimization",
            "output functions",
            "text classification models"
        ]
    },
    {
        "query": "monte carlo dropout",
        "true_parents": [
            "interpretability"
        ],
        "predictions": [
            "regularization",
            "generalization",
            "statistical inference",
            "approximate inference",
            "output functions",
            "distribution approximation",
            "markov chain monte carlo",
            "likelihood-based generative models",
            "robustness methods",
            "probability distribution representation"
        ]
    },
    {
        "query": "pythia",
        "true_parents": [
            "language models"
        ],
        "predictions": [
            "language models",
            "autoregressive transformers",
            "generative sequence models",
            "autoencoding transformers",
            "sequence to sequence models",
            "likelihood-based generative models",
            "transformers",
            "language model pre-training",
            "code generation transformers",
            "textual inference models"
        ]
    },
    {
        "query": "convolution",
        "true_parents": [
            "convolutions"
        ],
        "predictions": [
            "convolutions",
            "convolutional neural networks",
            "image models",
            "kernel methods",
            "parameter sharing",
            "output functions",
            "feature extractors",
            "image feature extractors",
            "image representations",
            "image manipulation models"
        ]
    },
    {
        "query": "contrastive bert",
        "true_parents": [
            "rl transformers"
        ],
        "predictions": [
            "language models",
            "rl transformers",
            "textual inference models",
            "offline reinforcement learning methods",
            "autoencoding transformers",
            "language model pre-training",
            "sequence to sequence models",
            "meta-learning algorithms",
            "text instance representations",
            "multi-modal methods"
        ]
    },
    {
        "query": "distribution-induced bidirectional generative adversarial network for graph representation learning",
        "true_parents": [
            "graph embeddings"
        ],
        "predictions": [
            "graph models",
            "graph embeddings",
            "graph representation learning",
            "graph data augmentation",
            "representation learning",
            "likelihood-based generative models",
            "generalization",
            "generative models",
            "semi-supervised learning methods",
            "output functions"
        ]
    },
    {
        "query": "reinforce",
        "true_parents": [
            "policy gradient methods"
        ],
        "predictions": [
            "policy gradient methods",
            "reinforcement learning frameworks",
            "offline reinforcement learning methods",
            "actor-critic algorithms",
            "value function estimation",
            "on-policy td control",
            "output functions",
            "optimization",
            "control and decision systems",
            "markov chain monte carlo"
        ]
    },
    {
        "query": "balanced selection",
        "true_parents": [
            "active learning"
        ],
        "predictions": [
            "generalization",
            "taxonomy expansion models",
            "optimization",
            "hybrid optimization",
            "discriminators",
            "adaptive computation",
            "exploration strategies",
            "sequence decoding methods",
            "statistical inference",
            "textual meaning"
        ]
    },
    {
        "query": "filter response normalization",
        "true_parents": [
            "normalization"
        ],
        "predictions": [
            "convolutional neural networks",
            "convolutions",
            "feature extractors",
            "activation functions",
            "explainable cnns",
            "output functions",
            "adaptive activation functions",
            "image models",
            "normalization",
            "loss functions"
        ]
    },
    {
        "query": "bigbigan",
        "true_parents": [
            "self-supervised learning",
            "generative models",
            "generative adversarial networks"
        ],
        "predictions": [
            "image generation models",
            "generative models",
            "generative audio models",
            "image models",
            "likelihood-based generative models",
            "generative video models",
            "generative adversarial networks",
            "image manipulation models",
            "reversible image conversion models",
            "generative sequence models"
        ]
    },
    {
        "query": "superpixelgridcut, superpixelgridmean, superpixelgridmix",
        "true_parents": [
            "image data augmentation"
        ],
        "predictions": [
            "image data augmentation",
            "image segmentation models",
            "semantic segmentation modules",
            "video data augmentation",
            "semantic segmentation models",
            "feature extractors",
            "image manipulation models",
            "image semantic segmentation metric",
            "text data augmentation",
            "medical image models"
        ]
    },
    {
        "query": "zero-bounded log-sum-exp & pairwise rank-based loss",
        "true_parents": [
            "loss functions"
        ],
        "predictions": [
            "loss functions",
            "output functions",
            "optimization",
            "structured prediction",
            "learning to rank models",
            "generalization",
            "discriminators",
            "distributions",
            "statistical inference",
            "likelihood-based generative models"
        ]
    },
    {
        "query": "cornernet",
        "true_parents": [
            "one-stage object detection models",
            "object detection models"
        ],
        "predictions": [
            "object detection models",
            "object detection modules",
            "oriented object detection models",
            "one-stage object detection models",
            "convolutional neural networks",
            "image models",
            "roi feature extractors",
            "region proposal",
            "localization models",
            "arbitrary object detectors"
        ]
    },
    {
        "query": "you only hypothesize once",
        "true_parents": [
            "point cloud models"
        ],
        "predictions": [
            "point cloud representations",
            "geometric matching",
            "6d pose estimation models",
            "slam methods",
            "representation learning",
            "localization models",
            "generalization",
            "point cloud models",
            "3d representations",
            "feature extractors"
        ]
    },
    {
        "query": "roiwarp",
        "true_parents": [
            "roi feature extractors"
        ],
        "predictions": [
            "roi feature extractors",
            "pooling operations",
            "object detection models",
            "oriented object detection models",
            "region proposal",
            "object detection modules",
            "instance segmentation modules",
            "convolutional neural networks",
            "localization models",
            "instance segmentation models"
        ]
    },
    {
        "query": "gan hinge loss",
        "true_parents": [
            "loss functions"
        ],
        "predictions": [
            "generative adversarial networks",
            "generative models",
            "loss functions",
            "image generation models",
            "discriminators",
            "output functions",
            "generative training",
            "likelihood-based generative models",
            "generative video models",
            "generalization"
        ]
    },
    {
        "query": "receptive field block",
        "true_parents": [
            "feature extractors"
        ],
        "predictions": [
            "convolutional neural networks",
            "image model blocks",
            "pooling operations",
            "feature extractors",
            "object detection models",
            "object detection modules",
            "image feature extractors",
            "image models",
            "medical image models",
            "convolutions"
        ]
    },
    {
        "query": "nearest-neighbor contrastive learning of visual representations",
        "true_parents": [
            "self-supervised learning"
        ],
        "predictions": [
            "self-supervised learning",
            "representation learning",
            "image representations",
            "feature extractors",
            "loss functions",
            "image models",
            "image feature extractors",
            "video-text retrieval models",
            "document understanding models",
            "image model blocks"
        ]
    },
    {
        "query": "momentumized, adaptive, dual averaged gradient",
        "true_parents": [
            "stochastic optimization"
        ],
        "predictions": [
            "meta-learning algorithms",
            "optimization",
            "hybrid optimization",
            "adaptive computation",
            "stochastic optimization",
            "parameter server methods",
            "large batch optimization",
            "generalization",
            "learning rate schedules",
            "output functions"
        ]
    },
    {
        "query": "modular interactive vos",
        "true_parents": [
            "video object segmentation models"
        ],
        "predictions": [
            "video instance segmentation models",
            "video object segmentation models",
            "video recognition models",
            "interactive semantic segmentation models",
            "instance segmentation modules",
            "semantic segmentation modules",
            "instance segmentation models",
            "video panoptic segmentation models",
            "image segmentation models",
            "semantic segmentation models"
        ]
    },
    {
        "query": "parrot",
        "true_parents": [
            "cache replacement models",
            "imitation learning methods"
        ],
        "predictions": [
            "cache replacement models",
            "offline reinforcement learning methods",
            "meta-learning algorithms",
            "imitation learning methods",
            "generalization",
            "output functions",
            "value function estimation",
            "copy mechanisms",
            "representation learning",
            "heuristic search algorithms"
        ]
    },
    {
        "query": "cross-covariance attention",
        "true_parents": [
            "attention mechanisms"
        ],
        "predictions": [
            "attention modules",
            "attention mechanisms",
            "language model components",
            "attention patterns",
            "feature extractors",
            "long-range interaction layers",
            "synthesized attention mechanisms",
            "attention",
            "transformers",
            "generalization"
        ]
    },
    {
        "query": "path length regularization",
        "true_parents": [
            "regularization"
        ],
        "predictions": [
            "generative models",
            "generative adversarial networks",
            "regularization",
            "image generation models",
            "likelihood-based generative models",
            "loss functions",
            "image manipulation models",
            "optimization",
            "representation learning",
            "parameter norm penalties"
        ]
    },
    {
        "query": "self-cure network",
        "true_parents": [
            "regularization"
        ],
        "predictions": [
            "face recognition models",
            "face restoration models",
            "generalization",
            "discriminators",
            "regularization",
            "semi-supervised learning methods",
            "self-training methods",
            "medical image models",
            "graph models",
            "sample re-weighting"
        ]
    },
    {
        "query": "magface",
        "true_parents": [
            "face recognition models"
        ],
        "predictions": [
            "face recognition models",
            "loss functions",
            "discriminators",
            "feature extractors",
            "image models",
            "image quality models",
            "image representations",
            "convolutional neural networks",
            "output functions",
            "representation learning"
        ]
    },
    {
        "query": "inception-b",
        "true_parents": [
            "image model blocks"
        ],
        "predictions": [
            "image model blocks",
            "image models",
            "backbone architectures",
            "feature extractors",
            "image feature extractors",
            "convolutional neural networks",
            "medical image models",
            "video recognition models",
            "image manipulation models",
            "object detection modules"
        ]
    },
    {
        "query": "concatenated skip connection",
        "true_parents": [
            "skip connections"
        ],
        "predictions": [
            "skip connections",
            "skip connection blocks",
            "backbone architectures",
            "feature extractors",
            "image models",
            "image model blocks",
            "convolutional neural networks",
            "feedforward networks",
            "parameter sharing",
            "pooling operations"
        ]
    },
    {
        "query": "memory-associated differential learning",
        "true_parents": [
            "semi-supervised learning methods"
        ],
        "predictions": [
            "generalization",
            "meta-learning algorithms",
            "lifelong learning",
            "textual inference models",
            "semi-supervised learning methods",
            "working memory models",
            "representation learning",
            "inference extrapolation",
            "statistical inference",
            "self-training methods"
        ]
    },
    {
        "query": "memory network",
        "true_parents": [
            "working memory models"
        ],
        "predictions": [
            "question answering models",
            "textual inference models",
            "generalization",
            "textual meaning",
            "graph models",
            "working memory models",
            "output functions",
            "information retrieval methods",
            "entity retrieval models",
            "recurrent neural networks"
        ]
    },
    {
        "query": "swapping assignments between views",
        "true_parents": [
            "self-supervised learning"
        ],
        "predictions": [
            "self-supervised learning",
            "image data augmentation",
            "representation learning",
            "clustering",
            "video data augmentation",
            "reversible image conversion models",
            "video recognition models",
            "video-text retrieval models",
            "image representations",
            "semi-supervised learning methods"
        ]
    },
    {
        "query": "cutblur",
        "true_parents": [
            "image data augmentation"
        ],
        "predictions": [
            "image data augmentation",
            "image restoration models",
            "image super-resolution models",
            "video data augmentation",
            "image manipulation models",
            "super-resolution models",
            "image scaling strategies",
            "video super-resolution models",
            "multi-scale training",
            "feature upsampling"
        ]
    },
    {
        "query": "adaptive meta optimizer",
        "true_parents": [
            "stochastic optimization"
        ],
        "predictions": [
            "hybrid optimization",
            "optimization",
            "meta-learning algorithms",
            "adaptive computation",
            "hybrid parallel methods",
            "stochastic optimization",
            "learning rate schedules",
            "output functions",
            "generalization",
            "hyperparameter search"
        ]
    },
    {
        "query": "location sensitive attention",
        "true_parents": [
            "attention mechanisms"
        ],
        "predictions": [
            "attention patterns",
            "attention modules",
            "synthesized attention mechanisms",
            "attention",
            "transformers",
            "sequence to sequence models",
            "long-range interaction layers",
            "attention mechanisms",
            "copy mechanisms",
            "output functions"
        ]
    },
    {
        "query": "voxel r-cnn",
        "true_parents": [
            "point cloud models",
            "3d object detection models"
        ],
        "predictions": [
            "object detection models",
            "3d object detection models",
            "point cloud representations",
            "object detection modules",
            "oriented object detection models",
            "localization models",
            "3d representations",
            "convolutional neural networks",
            "region proposal",
            "feature extractors"
        ]
    },
    {
        "query": "low-level backbone",
        "true_parents": [
            "feature extractors"
        ],
        "predictions": [
            "backbone architectures",
            "feature extractors",
            "image models",
            "convolutional neural networks",
            "representation learning",
            "image feature extractors",
            "light-weight neural networks",
            "generalization",
            "pooling operations",
            "image representations"
        ]
    },
    {
        "query": "spatial attention module",
        "true_parents": [
            "attention modules",
            "image model blocks"
        ],
        "predictions": [
            "attention modules",
            "pooling operations",
            "convolutional neural networks",
            "explainable cnns",
            "feature extractors",
            "attention patterns",
            "attention mechanisms",
            "image feature extractors",
            "image models",
            "attention"
        ]
    },
    {
        "query": "dynamic algorithm configuration",
        "true_parents": [
            "hyperparameter search"
        ],
        "predictions": [
            "adaptive computation",
            "optimization",
            "hyperparameter search",
            "generalization",
            "control and decision systems",
            "hybrid optimization",
            "heuristic search algorithms",
            "meta-learning algorithms",
            "stochastic optimization",
            "automl"
        ]
    },
    {
        "query": "true online td lambda",
        "true_parents": [
            "on-policy td control"
        ],
        "predictions": [
            "off-policy td control",
            "eligibility traces",
            "on-policy td control",
            "value function estimation",
            "meta-learning algorithms",
            "output functions",
            "textual inference models",
            "reinforcement learning frameworks",
            "generalization",
            "offline reinforcement learning methods"
        ]
    },
    {
        "query": "variational inference",
        "true_parents": [
            "dimensionality reduction"
        ],
        "predictions": [
            "approximate inference",
            "generative models",
            "distribution approximation",
            "statistical inference",
            "variational optimization",
            "generalization",
            "markov chain monte carlo",
            "likelihood-based generative models",
            "probability distribution representation",
            "optimization"
        ]
    },
    {
        "query": "deep deterministic policy gradient",
        "true_parents": [
            "policy gradient methods"
        ],
        "predictions": [
            "actor-critic algorithms",
            "policy gradient methods",
            "reinforcement learning frameworks",
            "value function estimation",
            "output functions",
            "control and decision systems",
            "offline reinforcement learning methods",
            "meta-learning algorithms",
            "optimization",
            "distributed reinforcement learning"
        ]
    },
    {
        "query": "hourglass module",
        "true_parents": [
            "image model blocks"
        ],
        "predictions": [
            "pose estimation models",
            "pose estimation blocks",
            "image model blocks",
            "semantic segmentation modules",
            "skip connections",
            "image models",
            "convolutional neural networks",
            "6d pose estimation models",
            "image feature extractors",
            "image manipulation models"
        ]
    },
    {
        "query": "autosync",
        "true_parents": [
            "distributed methods",
            "auto parallel methods"
        ],
        "predictions": [
            "hybrid parallel methods",
            "auto parallel methods",
            "optimization",
            "distributed methods",
            "data parallel methods",
            "adaptive computation",
            "parameter server methods",
            "sharded data parallel methods",
            "generalization",
            "asynchronous data parallel"
        ]
    },
    {
        "query": "zoomnet",
        "true_parents": [
            "pose estimation models"
        ],
        "predictions": [
            "pose estimation models",
            "pose estimation blocks",
            "motion prediction models",
            "6d pose estimation models",
            "convolutional neural networks",
            "output heads",
            "image models",
            "video recognition models",
            "document understanding models",
            "human object interaction detectors"
        ]
    },
    {
        "query": "enet",
        "true_parents": [
            "semantic segmentation models"
        ],
        "predictions": [
            "semantic segmentation models",
            "semantic segmentation modules",
            "image segmentation models",
            "convolutional neural networks",
            "image models",
            "backbone architectures",
            "light-weight neural networks",
            "image model blocks",
            "image semantic segmentation metric",
            "image feature extractors"
        ]
    },
    {
        "query": "mdtvsfa",
        "true_parents": [
            "video quality models"
        ],
        "predictions": [
            "generalization",
            "behaviour policies",
            "taxonomy expansion models",
            "textual meaning",
            "question answering models",
            "global context modules",
            "attention",
            "discriminators",
            "medical image models",
            "document understanding models"
        ]
    },
    {
        "query": "syntax heat parse tree",
        "true_parents": [
            "interpretability"
        ],
        "predictions": [
            "textual meaning",
            "interpretability",
            "structured prediction",
            "dependency parsers",
            "document understanding models",
            "layout annotation models",
            "language model components",
            "graph models",
            "generalization",
            "textual inference models"
        ]
    }
]